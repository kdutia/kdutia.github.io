hello! I'm ~~founding data scientist~~ ~~head of data science~~ senior data scientist at nonprofit [Climate Policy Radar](https://climatepolicyradar.org/) where we're building free, open tools which use natural language processing (NLP) to improve climate decision-making from documents.

my work is broadly centered on NLP, climate change and how to do the former responsibly and collaboratively in the context of the latter. this includes:

**building things**, such as

- parts of each iteration of our [climate policy knowledge graph and (re)search tool](https://app.climatepolicyradar.org)
- collaborative research, on
  - [responsible RAG for climate decision-making from documents](https://arxiv.org/abs/2410.23902) (2024)
  - [identifying climate targets in national laws and policies using machine learning](https://www.climatechange.ai/papers/iclr2024/26) (ICLR 2024)
- a technical analysis tool [for the First Global Stocktake](https://gst1.org/), partnered with the UNFCCC

**supporting the broader community** through organising events and online spaces, and doing talks

- co-organised the [first](https://aclanthology.org/volumes/2024.climatenlp-1/) and [second](https://aclanthology.org/volumes/2025.climatenlp-1/) climate NLP workshops at ACL (2024-5)
- co-founded an [online, active community for people working on Climate NLP](https://climatenlpcommunity.github.io/)
- co-wrote a [tutorial on using our open knowledge graph for climate policy analysis](https://neurips.cc/virtual/2025/loc/san-diego/poster/127006) (NeurIPS 2025)
- gave talks on
  - [impact, equity and community in our data science](/talks/2024_CPR_at_Nesta_data_science_away_day.pdf) at Nesta (2024)
  - [a policy evidence base as a knowledge graph](https://docs.google.com/presentation/d/1MbYrCa1fhcU7v1X-gLh2sxWonxJpw9uZ5Eiy7qLbRt8/edit#slide=id.g104591c5ed4_0_0) at the Turing Institute (2023)

before Climate Policy Radar I was lead developer on the [Heritage Connector](https://www.sciencemuseumgroup.org.uk/projects/heritage-connector) project, which built a system for building knowledge graphs from museum collections using NLP and Wikidata. we wrote a [peer-reviewed paper](https://doi.org/10.1002/ail2.23), maintained [a blog](https://thesciencemuseum.github.io/heritageconnector/), and showed off some of our demos in a [final talk](https://www.youtube.com/watch?v=IVV08dun_jY&list=PLRIxrpy54RHbqCRlYysM9vX_LStbDJ3Ov&index=2).

you can also find me on [linkedin](https://www.linkedin.com/in/kalyandutia/), [github](https://github.com/kdutia/), [bandcamp](https://bandcamp.com/kdutia) and [google scholar](https://scholar.google.com/citations?user=JHYa6iUAAAAJ&hl=en&citsig=ACUpqDdNBMZEw8G96rKo9A5pLDLD).